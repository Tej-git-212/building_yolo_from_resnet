{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom IPython.display import clear_output\nimport itertools, re, os, random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nimport matplotlib\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom pylab import rcParams\nfrom tensorflow.keras.models import Sequential, save_model\n\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization, Input, concatenate, Reshape, Conv2DTranspose, Conv2D, MaxPool2D, GlobalAveragePooling2D\nfrom tensorflow.keras import layers, Input, Model, models, regularizers, optimizers\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\n#from tensorflow.keras.utils import np_utils\n\n\nfrom sklearn.utils import class_weight\n\nimport tensorflow_addons as tfa\n\nfrom tensorflow.keras.layers import Conv1D, Convolution1D, MaxPooling1D\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import MobileNetV2\nimport math\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport seaborn as sns\nimport matplotlib.image as mpimg\nimport plotly.express as px\n#from tensorflow.keras.utils.vis_utils import plot_model\n\nfrom numpy import expand_dims\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\n\nimport math\nimport os\nfrom tensorflow.keras import initializers\nimport gc\nfrom random import randint\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer, Dropout, Flatten, Reshape\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Lambda\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import LeakyReLU\nfrom functools import partial\nfrom tensorflow.keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:16.290337Z","iopub.execute_input":"2021-11-17T19:19:16.290674Z","iopub.status.idle":"2021-11-17T19:19:16.307253Z","shell.execute_reply.started":"2021-11-17T19:19:16.290641Z","shell.execute_reply":"2021-11-17T19:19:16.306604Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, InputLayer, Dropout, Flatten, Reshape\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\ndef simp(x):\n    return tf.keras.activations.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:16.308690Z","iopub.execute_input":"2021-11-17T19:19:16.309045Z","iopub.status.idle":"2021-11-17T19:19:16.325961Z","shell.execute_reply.started":"2021-11-17T19:19:16.309018Z","shell.execute_reply":"2021-11-17T19:19:16.324993Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def my_loss_fn(y_true, y_pred):\n\n    y_true = tf.reshape(y_true, (-1,individual,individual,(((each_sizei*(sizei+5))+1))))\n    y_pred = tf.reshape(y_pred, (-1,individual,individual,(((each_sizei*(sizei+5))+1))))\n    \n    conf_loss1 = tf.reduce_sum(tf.square(y_true[:,:,:,:1]-y_pred[:,:,:,:1]))\n    conf_loss2 = tf.reduce_sum(tf.square(y_true[:,:,:,1:2]-y_pred[:,:,:,1:2]))\n    conf_loss3 = tf.reduce_sum(tf.square(y_true[:,:,:,8:9]-y_pred[:,:,:,8:9]))\n    conf_loss4 = tf.reduce_sum(tf.square(y_true[:,:,:,15:16]-y_pred[:,:,:,15:16]))\n    conf_loss5 = tf.reduce_sum(tf.square(y_true[:,:,:,22:23]-y_pred[:,:,:,22:23]))\n    conf_loss6 = tf.reduce_sum(tf.square(y_true[:,:,:,29:30]-y_pred[:,:,:,29:30]))\n    conf_loss7 = tf.reduce_sum(tf.square(y_true[:,:,:,36:37]-y_pred[:,:,:,36:37]))\n    conf_loss8 = tf.reduce_sum(tf.square(y_true[:,:,:,43:44]-y_pred[:,:,:,43:44]))\n    \n    conf_loss = conf_loss1+conf_loss2+conf_loss3+conf_loss4+conf_loss5+conf_loss6+conf_loss7+conf_loss8\n    lodu_mask=tf.reshape(y_true[:,:,:,:1],(-1,individual,individual))\n    modi_true = tf.boolean_mask(y_true[:,:,:,1:],lodu_mask)\n    modi_pred = tf.boolean_mask(y_pred[:,:,:,1:],lodu_mask)\n    modi_true = tf.reshape(modi_true,(-1,7,7))\n    modi_pred = tf.reshape(modi_pred,(-1,7,7))\n    \n    modi_mask = tf.reshape(modi_true[:,:,:1],(-1,7))\n    \n    modi_class_true = tf.boolean_mask(modi_true[:,:,1:3],modi_mask)\n    modi_class_pred = tf.boolean_mask(modi_pred[:,:,1:3],modi_mask)\n    \n    modi_box_true = tf.boolean_mask(modi_true[:,:,3:],modi_mask)\n    modi_box_pred = tf.boolean_mask(modi_pred[:,:,3:],modi_mask)\n    \n    modi_class_true = tf.reshape(modi_class_true,(-1,2))\n    modi_class_pred = tf.reshape(modi_class_pred,(-1,2))\n    \n    modi_box_true = tf.reshape(modi_box_true,(-1,4))\n    modi_box_pred = tf.reshape(modi_box_pred,(-1,4))\n    \n    modi_class_pred = tf.nn.softmax(modi_class_pred)\n    \n    loss_obj = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n    class_loss = tf.reduce_sum(loss_obj(modi_class_true, modi_class_pred))\n    \n    center_loss = tf.reduce_sum(tf.abs(modi_box_true[:,:2]-modi_box_pred[:,:2]))/batch_size\n    \n    box_loss = tf.reduce_sum(tf.abs(modi_box_true[:,2:]-modi_box_pred[:,2:]))\n    area_loss = tf.reduce_sum(tf.abs(tf.math.multiply(modi_box_true[:,2:3],modi_box_true[:,3:]) - tf.math.multiply(modi_box_pred[:,2:3],modi_box_pred[:,3:])))\n    \n    iou_loss = cal_iou(modi_box_true,modi_box_pred)\n    \n    conf_loss = conf_loss/batch_size\n    center_loss = center_loss/batch_size\n    box_loss = box_loss/batch_size\n    iou_loss = iou_loss/batch_size\n    area_loss = area_loss/batch_size\n    \n    sumi = (2.0*conf_loss)+(2.0*class_loss)+(2.0*center_loss)+(3.0*box_loss) + (3.0*area_loss) +(3.0*iou_loss)\n    return sumi","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:16.327649Z","iopub.execute_input":"2021-11-17T19:19:16.328185Z","iopub.status.idle":"2021-11-17T19:19:16.353965Z","shell.execute_reply.started":"2021-11-17T19:19:16.328143Z","shell.execute_reply":"2021-11-17T19:19:16.352968Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"model = load_model('../input/yolo-model/best_model.h5',custom_objects={ 'my_loss_fn': my_loss_fn })\nmodel.save('todel.h5')\ngkjlgk","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:54:20.030375Z","iopub.execute_input":"2021-11-17T08:54:20.030567Z","iopub.status.idle":"2021-11-17T08:54:33.500445Z","shell.execute_reply.started":"2021-11-17T08:54:20.030544Z","shell.execute_reply":"2021-11-17T08:54:33.498206Z"}}},{"cell_type":"code","source":"a=tf.constant([[0.0,0.0,1.0],[1.0,0.0,0.0]])\nb=tf.constant([[0.1,0.4,0.6],[0.5,0.3,0.3]])\nb = tf.nn.softmax(b)\ncce = tf.keras.losses.CategoricalCrossentropy()\ncce(a, b)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:16.355361Z","iopub.execute_input":"2021-11-17T19:19:16.355640Z","iopub.status.idle":"2021-11-17T19:19:16.379837Z","shell.execute_reply.started":"2021-11-17T19:19:16.355610Z","shell.execute_reply":"2021-11-17T19:19:16.379093Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"pretrained_model = tf.keras.applications.ResNet50(input_shape=(image_size, image_size, 3),include_top=False,weights='imagenet',pooling='max')\npretrained_model = Model(inputs=pretrained_model.inputs, outputs=pretrained_model.layers[-2].output)\npretrained_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-15T20:33:33.473007Z","iopub.execute_input":"2021-11-15T20:33:33.473368Z","iopub.status.idle":"2021-11-15T20:33:35.25279Z","shell.execute_reply.started":"2021-11-15T20:33:33.473327Z","shell.execute_reply":"2021-11-15T20:33:35.252107Z"}}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:16.381624Z","iopub.execute_input":"2021-11-17T19:19:16.382059Z","iopub.status.idle":"2021-11-17T19:19:16.583460Z","shell.execute_reply.started":"2021-11-17T19:19:16.382026Z","shell.execute_reply":"2021-11-17T19:19:16.582457Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# BigQuery\nfrom google.cloud import bigquery\nbigquery_client = bigquery.Client(project='YOUR PROJECT ID')\n\n# Cloud Storage\nfrom google.cloud import storage\nstorage_client = storage.Client(project='YOUR PROJECT ID')\n\n# Cloud AutoML\nfrom google.cloud import automl_v1beta1 as automl\nautoml_client = automl.AutoMlClient()\n\n# Cloud Translation\nfrom google.cloud import translate_v2\ntranslate_client = translate_v2.Client()\n\n# Cloud Natural Language\nfrom google.cloud import language_v1\nclient = language_v1.LanguageServiceClient()\n\n# Cloud Video Intelligence\nfrom google.cloud import videointelligence\nvideo_client = videointelligence.VideoIntelligenceServiceClient()\n\n# Cloud Vision\nfrom google.cloud import vision\nclient = vision.ImageAnnotatorClient()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:16.584989Z","iopub.execute_input":"2021-11-17T19:19:16.585338Z","iopub.status.idle":"2021-11-17T19:19:16.596913Z","shell.execute_reply.started":"2021-11-17T19:19:16.585295Z","shell.execute_reply":"2021-11-17T19:19:16.596002Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n    print(\"Device:\", tpu.master())\n    strategy = tf.distribute.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint(\"Number of replicas:\", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:16.598270Z","iopub.execute_input":"2021-11-17T19:19:16.599085Z","iopub.status.idle":"2021-11-17T19:19:25.029578Z","shell.execute_reply.started":"2021-11-17T19:19:16.599039Z","shell.execute_reply":"2021-11-17T19:19:25.028631Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"batch_size=64\nimage_size=512\nsizei=2\neach_sizei=7\ntotal_sizei=25\nchannels_size=3\nglobal extreme\nindividual=5\n\n\n# p=pd.read_csv('../input/hatworkers/Self Driving Car.v3-fixed-small.darknet/export/_darknet.labels', header=None)\n# d={}\n# for i in range(len(p)):\n#     d[i]=p[0][i]\n    \nglobal no_of_anchors,no_of_classes,threshold, thresh_iou,max_box\nno_of_anchors=each_sizei\nno_of_classes=sizei\nthreshold=0.6\nthreshold_iou=0.3\nmax_box=10\nglobal lodu\nglobal dick\nlodu = tf.zeros([individual,])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:25.032721Z","iopub.execute_input":"2021-11-17T19:19:25.033176Z","iopub.status.idle":"2021-11-17T19:19:25.041406Z","shell.execute_reply.started":"2021-11-17T19:19:25.033130Z","shell.execute_reply":"2021-11-17T19:19:25.040281Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold):\n    box_class_probs = tf.nn.softmax(box_class_probs)\n    box_scores = box_confidence*box_class_probs\n    box_classes = tf.math.argmax(box_scores,axis=-1)\n    box_class_scores = tf.reduce_max(box_scores,keepdims=False, axis=-1)\n    filtering_mask = box_class_scores>=threshold\n    scores = tf.boolean_mask(box_class_scores,filtering_mask)\n    boxes = tf.boolean_mask(boxes,filtering_mask)\n    classes = tf.boolean_mask(box_classes,filtering_mask)\n    return scores, boxes, classes\n\n\ndef iou(box1, box2):\n    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n    xi1 = max(box1_x1,box2_x1)\n    yi1 = max(box1_y1,box2_y1)\n    xi2 = min(box1_x2,box2_x2)\n    yi2 = min(box1_y2,box2_y2)\n    inter_width = max(xi2-xi1,0)\n    inter_height = max(yi2-yi1,0)\n    inter_area = inter_width*inter_height\n    box1_area = abs(box1_x2-box1_x1)*abs(box1_y2-box1_y1)\n    box2_area = abs(box2_x2-box2_x1)*abs(box2_y2-box2_y1)\n    union_area = box1_area+box2_area-inter_area\n    iou = inter_area/union_area\n    return iou\n\ndef yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold):\n    max_boxes_tensor = tf.Variable(max_boxes, dtype='int32')\n    nms_indices = tf.image.non_max_suppression(boxes,scores,max_boxes,iou_threshold=iou_threshold,name=None)\n    scores = tf.gather(scores, nms_indices, validate_indices=None, axis=None, batch_dims=0, name=None)\n    boxes = tf.gather(boxes, nms_indices, validate_indices=None, axis=None, batch_dims=0, name=None)\n    classes = tf.gather(classes, nms_indices, validate_indices=None, axis=None, batch_dims=0, name=None)\n    return scores, boxes, classes\n\ndef yolo_boxes_to_corners(box_xy, box_wh):\n    box_mins = box_xy - (box_wh / 2.)\n    box_maxes = box_xy + (box_wh / 2.)\n    return tf.keras.backend.concatenate([\n        box_mins[:,:,:,:,1:2],  # y_min\n        box_mins[:,:,:,:,0:1],  # x_min\n        box_maxes[:,:,:,:,1:2],  # y_max\n        box_maxes[:,:,:,:,0:1]  # x_max\n    ])\n\ndef yolo_head(x):\n    boxes_=x[:,:,:,:,sizei+1:]\n    box_wh=x[:,:,:,:,3+sizei:]\n    box_xy=x[:,:,:,:,1+sizei:3+sizei]\n    confidence_=x[:,:,:,:,:1]\n    classes_=x[:,:,:,:,1:sizei+1]\n    boxes_ = yolo_boxes_to_corners(box_xy,box_wh)\n    scores,boxes,classes=yolo_filter_boxes(boxes_,confidence_,classes_,threshold)\n    scores,boxes,classes=yolo_non_max_suppression(scores,boxes,classes,max_box,threshold_iou)\n    return scores, boxes, classes\n\ndef yolo_boxer_to_corners(box_xy, box_wh):\n    box_mins = box_xy - (box_wh / 2.)\n    box_maxes = box_xy + (box_wh / 2.)\n    return tf.keras.backend.concatenate([\n        box_mins[:,0:1],  # y_min\n        box_mins[:,1:2],  # x_min\n        box_maxes[:,0:1],  # y_max\n        box_maxes[:,1:2]  # x_max\n    ])\n\ndef kali_iou(box1, box2):\n    (box1_x1, box1_y1, box1_x2, box1_y2) = box1[:,:1],box1[:,1:2],box1[:,2:3],box1[:,3:4]\n    (box2_x1, box2_y1, box2_x2, box2_y2) = box2[:,:1],box2[:,1:2],box2[:,2:3],box2[:,3:4]\n    xi1 = tf.math.maximum(box1_x1,box2_x1)\n    yi1 = tf.math.maximum(box1_y1,box2_y1)\n    xi2 = tf.math.minimum(box1_x2,box2_x2)\n    yi2 = tf.math.minimum(box1_y2,box2_y2)\n    inter_width = tf.math.maximum(xi2-xi1,0)\n    inter_height = tf.math.maximum(yi2-yi1,0)\n    inter_area = inter_width*inter_height\n    box1_area = tf.math.abs(box1_x2-box1_x1)*tf.math.abs(box1_y2-box1_y1)\n    box2_area = tf.math.abs(box2_x2-box2_x1)*tf.math.abs(box2_y2-box2_y1)\n    union_area = box1_area+box2_area-inter_area\n    iou = inter_area/union_area\n    return iou\n\n\ndef cal_iou(original,pred):\n    box_wh = original[:,2:]\n    box_wh_pred = pred[:,2:]\n    box_xy = original[:,:2]\n    box_xy_pred = pred[:,:2]\n    boxes_original = yolo_boxer_to_corners(box_xy,box_wh)\n    boxes_pred = yolo_boxer_to_corners(box_xy_pred,box_wh_pred)\n    score = kali_iou(boxes_original,boxes_pred)\n    usei = tf.ones_like(score)\n    bce = tf.keras.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n    return tf.reduce_sum(bce(score, usei))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:25.043128Z","iopub.execute_input":"2021-11-17T19:19:25.043457Z","iopub.status.idle":"2021-11-17T19:19:25.077981Z","shell.execute_reply.started":"2021-11-17T19:19:25.043416Z","shell.execute_reply":"2021-11-17T19:19:25.076748Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**masks**","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_datasets import KaggleDatasets\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nplt.style.use('ggplot')\n\nIMAGE_SIZE = [512, 512]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:25.079373Z","iopub.execute_input":"2021-11-17T19:19:25.079769Z","iopub.status.idle":"2021-11-17T19:19:25.096925Z","shell.execute_reply.started":"2021-11-17T19:19:25.079724Z","shell.execute_reply":"2021-11-17T19:19:25.095439Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:25.098297Z","iopub.execute_input":"2021-11-17T19:19:25.098711Z","iopub.status.idle":"2021-11-17T19:19:25.650418Z","shell.execute_reply.started":"2021-11-17T19:19:25.098671Z","shell.execute_reply":"2021-11-17T19:19:25.649358Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"FILENAMES = tf.io.gfile.glob(GCS_PATH + \"/tfrecords/*.tfrec\")\nsplit_ind = int(0.9 * len(FILENAMES))\nTRAINING_FILENAMES, VALID_FILENAMES = FILENAMES[:split_ind], FILENAMES[split_ind:]\nprint(\"Train TFRecord Files:\", len(TRAINING_FILENAMES))\nprint(\"Validation TFRecord Files:\", len(VALID_FILENAMES))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:25.651686Z","iopub.execute_input":"2021-11-17T19:19:25.651918Z","iopub.status.idle":"2021-11-17T19:19:25.732810Z","shell.execute_reply.started":"2021-11-17T19:19:25.651892Z","shell.execute_reply":"2021-11-17T19:19:25.731659Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def parse_tfrecord_fn(example):\n    feature_description = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"label\": tf.io.VarLenFeature(tf.float32)\n    }\n    example = tf.io.parse_single_example(example, feature_description)\n    example[\"image\"] = tf.io.decode_jpeg(example[\"image\"], channels=3)\n    example[\"label\"] = tf.sparse.to_dense(example[\"label\"])\n    return example\n\n\ndef prepare_sample(features):\n    image = tf.image.resize(features[\"image\"], size=(512, 512))\n    return image, features[\"label\"]\n\n\ndef get_dataset(filenames, batch_size):\n    dataset = (\n        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n        .map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n        .map(prepare_sample, num_parallel_calls=AUTOTUNE)\n        .map(data_augment, num_parallel_calls=AUTOTUNE)\n        .shuffle(batch_size * 10)\n        .batch(batch_size)\n        .prefetch(AUTOTUNE)\n    )\n    return dataset\n\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\n\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_saturation(image, 0, 2)\n    image=tf.image.random_brightness(image, 0.1)\n    return image, label  ","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:25.734246Z","iopub.execute_input":"2021-11-17T19:19:25.734595Z","iopub.status.idle":"2021-11-17T19:19:25.747496Z","shell.execute_reply.started":"2021-11-17T19:19:25.734562Z","shell.execute_reply":"2021-11-17T19:19:25.746474Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"STEPS_PER_EPOCH = count_data_items(TRAINING_FILENAMES)// batch_size\nVALIDATION_STEPS = -(-count_data_items(VALID_FILENAMES) // batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:25.748712Z","iopub.execute_input":"2021-11-17T19:19:25.749091Z","iopub.status.idle":"2021-11-17T19:19:25.766655Z","shell.execute_reply.started":"2021-11-17T19:19:25.749062Z","shell.execute_reply":"2021-11-17T19:19:25.765763Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"tfrecords_dir = GCS_PATH+'/tfrecords'\nnum_samples=2980\nraw_dataset = tf.data.TFRecordDataset(f\"{tfrecords_dir}/file_00-{num_samples}.tfrec\")\nparsed_dataset = raw_dataset.map(parse_tfrecord_fn)\n\n\nfor features in parsed_dataset.take(1):\n    for key in features.keys():\n        if key != \"image\":\n            print(len(features[key]))\n            print(f\"{key}: {features[key]}\")\n\n    print(f\"Image shape: {features['image'].shape}\")\n    plt.figure(figsize=(7, 7))\n    plt.imshow(features[\"image\"].numpy())\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:25.767880Z","iopub.execute_input":"2021-11-17T19:19:25.768230Z","iopub.status.idle":"2021-11-17T19:19:27.617540Z","shell.execute_reply.started":"2021-11-17T19:19:25.768191Z","shell.execute_reply":"2021-11-17T19:19:27.616265Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def draw_boxes(image_file, out_boxes, out_classes, out_scores):\n    import matplotlib.pyplot as plt\n    from matplotlib.patches import Rectangle\n    from PIL import Image\n    xt = pd.DataFrame(out_boxes.numpy(), columns = ['y1', 'x1', 'y2', 'x2'])\n    xt=xt*512\n    xt['scores']=out_scores.numpy()\n    xt['label']=out_classes.numpy()\n    xt['w'] = (xt['x2'] - xt['x1']).abs()\n    xt['h'] = (xt['y2'] - xt['y1']).abs()\n    \n    xt['x']=(xt['x1']+ (xt['w']*0.5))\n    xt['y']=(xt['y1']+ (xt['h']*0.5))\n    plt.imshow(Image.open(image_file))\n    plt.grid(True)\n    for i in range(len(xt)):\n        x=xt.iloc[i:i+1,:]\n        x1=x['x1'].values\n        y1=x['y1'].values\n        w=x['w'].values\n        h=x['h'].values\n        la=x['label'].values\n        lb=x['scores'].values\n        x2=x['x'].values\n        y2=x['y'].values\n        color_of_box=color_box[la[0]][0]\n        color_of_label=color_box[la[0]][1]\n        legend_properties = {'weight':'bold'}\n        la=d[la[0]]\n        lb = str(round(lb[0], 2))\n        la = la + ' ('+lb+') '\n        text_x=x1\n        text_y=y1\n        plt.gca().add_patch(Rectangle((x1, y1), w, h, linewidth=1, edgecolor=color_of_box, facecolor='none',lw=1.3))\n        plt.plot(x2, y2, marker='.', color=\"white\")\n        plt.text(text_x, text_y, lb, fontsize=9, color=color_of_label)\n        plt.legend(prop=legend_properties)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:27.620490Z","iopub.execute_input":"2021-11-17T19:19:27.620818Z","iopub.status.idle":"2021-11-17T19:19:27.636187Z","shell.execute_reply.started":"2021-11-17T19:19:27.620786Z","shell.execute_reply":"2021-11-17T19:19:27.635032Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def predict(image_file,fj):\n    #image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n    from tensorflow.keras.models import load_model\n    import matplotlib.pyplot as plt\n    path='../input/fork-of-yolo-tpu/best_model.h5'\n    modeli = load_model(path, compile=False)\n    from keras.preprocessing import image\n    img = image.load_img(image_file, target_size=(image_size, image_size))\n    x = image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    a=modeli.predict(x)\n    a=tf.reshape(a,(1,individual,individual,((each_sizei*(sizei+5))+1)))\n    a=a[:,:,:,1:]\n    a=tf.reshape(a,(1,individual,individual,each_sizei,sizei+5))\n    \n    a=tf.reshape(fj,(1,individual,individual,((each_sizei*(sizei+5))+1)))\n    a=a[:,:,:,1:]\n    a=tf.reshape(a,(1,individual,individual,each_sizei,sizei+5))\n    out_scores, out_boxes, out_classes=yolo_head(a)\n    draw_boxes(image_file,out_boxes,out_classes,out_scores)\n\n    return out_scores, out_boxes, out_classes","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:27.637854Z","iopub.execute_input":"2021-11-17T19:19:27.638186Z","iopub.status.idle":"2021-11-17T19:19:27.653484Z","shell.execute_reply.started":"2021-11-17T19:19:27.638134Z","shell.execute_reply":"2021-11-17T19:19:27.652649Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def get_class_names(out_classes):\n    x=out_classes.numpy()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:27.654743Z","iopub.execute_input":"2021-11-17T19:19:27.654979Z","iopub.status.idle":"2021-11-17T19:19:27.669919Z","shell.execute_reply.started":"2021-11-17T19:19:27.654944Z","shell.execute_reply":"2021-11-17T19:19:27.669042Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"total_req=(sizei+5)*each_sizei*total_sizei\nprint(total_req)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:27.671050Z","iopub.execute_input":"2021-11-17T19:19:27.671485Z","iopub.status.idle":"2021-11-17T19:19:27.684934Z","shell.execute_reply.started":"2021-11-17T19:19:27.671439Z","shell.execute_reply":"2021-11-17T19:19:27.684144Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"a=tf.random.uniform((19,5), minval=0, maxval=1, dtype=tf.dtypes.float32, seed=None, name=None)\nb=tf.random.uniform((19,5), minval=0, maxval=1, dtype=tf.dtypes.float32, seed=None, name=None)\nprint(a)\nprint('\\n')\nprint(b)\nprint('\\n')\nmy_loss_fn(a,b)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T10:16:53.262002Z","iopub.execute_input":"2021-09-14T10:16:53.262587Z","iopub.status.idle":"2021-09-14T10:16:53.281864Z","shell.execute_reply.started":"2021-09-14T10:16:53.26255Z","shell.execute_reply":"2021-09-14T10:16:53.280872Z"}}},{"cell_type":"code","source":"def create_model():\n    encoder_input = layers.Input(shape=(image_size, image_size, channels_size), name=\"original_img\")\n    pretrained_model = tf.keras.applications.ResNet50(input_shape=(image_size, image_size, 3),include_top=False,weights='imagenet',pooling='max')\n    pretrained_model = Model(inputs=pretrained_model.inputs, outputs=pretrained_model.layers[-2].output)\n    pretrained_model.trainable = False\n    for layer in pretrained_model.layers[len(pretrained_model.layers)-6:]:\n        layer.trainable = True\n    x=pretrained_model(encoder_input)\n    x = Conv2D(512, (7,7), strides=(1,1), padding='valid', name='conv_third_last',use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros', activation='relu')(x)\n    x=layers.Dropout(0.2)(x)\n    x = Conv2D(128, (7,7), strides=(1,1), padding='valid', name='conv_second_last', use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros', activation='relu')(x)\n    x=layers.Dropout(0.1)(x)\n    x = Conv2D(64, (3,3), strides=(1,1), padding='same', use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros', name='conv_last1')(x)\n    x=layers.Dropout(0.1)(x)\n    x = Conv2D(15, (3,3), strides=(1,1), padding='valid', use_bias=True, kernel_initializer='glorot_uniform',bias_initializer='zeros', name='conv_last')(x)\n    x=layers.Dropout(0.1)(x)\n    x=layers.Flatten()(x)\n    encoder_output=layers.Dense(1250, activation='linear',kernel_initializer='glorot_uniform',bias_initializer='zeros')(x)\n    encoder = Model(encoder_input, encoder_output, name=\"encoder\")\n#     opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n    encoder.compile(optimizer='adam',loss=my_loss_fn)\n    return encoder","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:27.686135Z","iopub.execute_input":"2021-11-17T19:19:27.686789Z","iopub.status.idle":"2021-11-17T19:19:27.701210Z","shell.execute_reply.started":"2021-11-17T19:19:27.686754Z","shell.execute_reply":"2021-11-17T19:19:27.700174Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"train=get_dataset(TRAINING_FILENAMES, batch_size).repeat()\nvalid=get_dataset(VALID_FILENAMES, batch_size).repeat()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:27.702669Z","iopub.execute_input":"2021-11-17T19:19:27.703181Z","iopub.status.idle":"2021-11-17T19:19:27.895476Z","shell.execute_reply.started":"2021-11-17T19:19:27.703140Z","shell.execute_reply":"2021-11-17T19:19:27.894436Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True, patience=15)\nmodel = make_yolo(512,4096)\n\nhistory = model.fit(\n    x=get_dataset(VALID_FILENAMES,batch_size),\n    epochs=10,\n    steps_per_epoch=VALIDATION_STEPS,\n    validation_data=get_dataset(TRAINING_FILENAMES, batch_size),\n    validation_steps=STEPS_PER_EPOCH,\n    callbacks=[es, mc],\n    verbose=1\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T08:36:59.309294Z","iopub.execute_input":"2021-11-14T08:36:59.309833Z","iopub.status.idle":"2021-11-14T08:37:08.944993Z","shell.execute_reply.started":"2021-11-14T08:36:59.309788Z","shell.execute_reply":"2021-11-14T08:37:08.943824Z"}}},{"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\nmc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True, patience=50)\n\n# model = load_model('./todel.h5',custom_objects={ 'my_loss_fn': my_loss_fn })\n\nwith strategy.scope():\n#     model = load_model('./todel.h5',custom_objects={ 'my_loss_fn': my_loss_fn })\n    model = create_model()\n\nhistory = model.fit(\n    train,\n    epochs=100,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid,\n    validation_steps=VALIDATION_STEPS,\n    callbacks=[es, mc],\n    verbose=1\n)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T19:19:27.897011Z","iopub.execute_input":"2021-11-17T19:19:27.897583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model=create_model()\ntf.keras.utils.plot_model(model, to_file='Model1.png')\n#model=tf.keras.models.load_model('../input/model-weights/best_model.h5')\n#model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-12T17:04:51.699652Z","iopub.execute_input":"2021-11-12T17:04:51.700243Z","iopub.status.idle":"2021-11-12T17:04:54.87441Z","shell.execute_reply.started":"2021-11-12T17:04:51.700205Z","shell.execute_reply":"2021-11-12T17:04:54.873558Z"}}},{"cell_type":"code","source":"history = model.fit(\n    train,\n    epochs=200,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    validation_data=valid,\n    validation_steps=VALIDATION_STEPS,\n    callbacks=[es, mc],\n    verbose=1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predicty():\n    h=''\n    a=randint(0, 1)\n    if(a==0):\n        b=randint(0,len(train)-1)\n        h=train['image_path'][b]\n    if(a==1):\n        b=randint(0,len(test)-1)\n        h=test['image_path'][b]\n    gc.collect()\n    xm = train[train['image_path']==h]\n    if(len(xm)>0):\n        print('true')\n        xx = xm[xm.columns[:-1]].to_numpy()\n        predict(h,xx)\n    else:\n        print('false')\n        xm=test[test['image_path']==h]\n        xx = xm[xm.columns[:-1]].to_numpy()\n        predict(h,xx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicty()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def read_this(file):\n    file_name=os.path.splitext(file)[0]+'.txt'\n    path_csv = pd.read_csv(file_name, sep=\" \", header=None)\n    path_csv.columns=['label','x','y','w','h']\n    return path_csv","metadata":{"execution":{"iopub.status.busy":"2021-11-13T08:12:30.826977Z","iopub.status.idle":"2021-11-13T08:12:30.82783Z","shell.execute_reply.started":"2021-11-13T08:12:30.827602Z","shell.execute_reply":"2021-11-13T08:12:30.827626Z"}}},{"cell_type":"markdown","source":"read_this('../input/hatworkers/Self Driving Car.v3-fixed-small.darknet/export/1478019974679051391_jpg.rf.2cfb16685f4b257e8dcd0ee6514c0ff6.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-11-13T08:12:30.828956Z","iopub.status.idle":"2021-11-13T08:12:30.829786Z","shell.execute_reply.started":"2021-11-13T08:12:30.829541Z","shell.execute_reply":"2021-11-13T08:12:30.829566Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}